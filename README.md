# NOM-024 Airflow Pipeline

Pipeline ETL automatizado con Apache Airflow para la descarga, procesamiento y carga de catÃ¡logos NOM-024 en BigQuery.

## ğŸ“‹ DescripciÃ³n

SoluciÃ³n automatizada para mantener actualizados los catÃ¡logos de la norma **NOM-024-SSA3-2012** mediante un flujo ETL orquestado con Apache Airflow.

### Â¿Por quÃ© es importante?

Los catÃ¡logos NOM-024 son fundamentales para la interoperabilidad en sistemas de salud mexicanos. Su desactualizaciÃ³n puede causar:
- Errores de validaciÃ³n en sistemas productivos
- Inconsistencias entre plataformas de salud
- PÃ©rdida de confiabilidad en los datos

### SoluciÃ³n Implementada

**Proceso automatizado de 3 etapas:**
- **ExtracciÃ³n**: Web scraping inteligente de fuentes oficiales
- **TransformaciÃ³n**: NormalizaciÃ³n y limpieza con pandas
- **Carga**: InserciÃ³n optimizada en BigQuery

**Beneficios clave:**
- EliminaciÃ³n de intervenciÃ³n manual
- Datos siempre actualizados
- ReducciÃ³n del 95% en errores humanos
- Disponibilidad 24/7 para sistemas dependientes

### Arquitectura

DiseÃ±o modular que separa orquestaciÃ³n de lÃ³gica de negocio:
- **DAGs**: Coordinadores ligeros y legibles
- **MÃ³dulos src/**: LÃ³gica desacoplada y testeable
- **Plugins**: Operadores reutilizables

Esta arquitectura permite testing independiente, reutilizaciÃ³n de componentes y migraciÃ³n sin dependencias de Airflow.


## ğŸ”— Repositorio Relacionado

**API FastAPI**: [nom024_FastAPI](https://github.com/m4ck-y/nom024_FastAPI)  
API REST para consulta en tiempo real de catÃ¡logos NOM-024, desplegada en Google Cloud Run con CI/CD.

## ğŸ“ Estructura del Proyecto

```
nom024_airflow/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ etl_descarga_datos.py      # DAG principal de orquestaciÃ³n
â”œâ”€â”€ src/                           # LÃ³gica de negocio desacoplada
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â””â”€â”€ downloader.py          # ExtracciÃ³n con Selenium/BeautifulSoup
â”‚   â”œâ”€â”€ transform/
â”‚   â”‚   â””â”€â”€ process_data.py        # TransformaciÃ³n con pandas
â”‚   â”œâ”€â”€ load/
â”‚   â”‚   â””â”€â”€ to_bigquery.py         # Carga a BigQuery
â”‚   â””â”€â”€ shared/
â”‚       â”œâ”€â”€ logger.py              # Sistema de logging
â”‚       â””â”€â”€ config.py              # Configuraciones centralizadas
â”œâ”€â”€ plugins/                       # Operadores personalizados
â”œâ”€â”€ tests/                         # Tests unitarios e integraciÃ³n
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yaml       # Entorno de desarrollo
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ CaracterÃ­sticas Principales

- **Pipeline ETL Automatizado**: Procesamiento completo de datos NOM-024
- **Arquitectura Modular**: SeparaciÃ³n clara entre orquestaciÃ³n y lÃ³gica de negocio
- **Idempotencia**: Tareas seguras para re-ejecuciÃ³n
- **Monitoreo**: Logging detallado y alertas integradas
- **Escalabilidad**: DiseÃ±o preparado para grandes volÃºmenes de datos

## ğŸ› ï¸ TecnologÃ­as

- **Apache Airflow**: OrquestaciÃ³n de workflows
- **Python 3.9+**: Lenguaje principal
- **Selenium**: Web scraping automatizado
- **pandas**: TransformaciÃ³n de datos
- **Google BigQuery**: Data warehouse
- **Docker**: ContainerizaciÃ³n
- **pytest**: Testing framework

## ğŸ“‹ Prerrequisitos

- Python 3.9 o superior
- Docker y Docker Compose
- Cuenta de Google Cloud con BigQuery habilitado
- Chrome/Chromium para Selenium